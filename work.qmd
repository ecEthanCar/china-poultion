---
title: "Analyzing Airbnb Data"
subtitle: "Report"
format: pdf
---

```{r}
#| load-package
#| echo: false

library(tidyverse) 
library(skimr) 
library(jsonlite) 
library(scales) 
library(lubridate) 
library(knitr) 
library(kableExtra) 
library(patchwork) 
library(tidymodels) 
library(gridExtra) 
library(broom)
library(readxl)
library(dplyr)


theme_set(theme_minimal())
```

```{r}
#| import-data-for-reference

indicator_2016 <- read_excel("Shared_Data/Economic Indicators(China)2016.xlsx")
indicator_2017 <- read_excel("Shared_Data/Economic Indicators(China)2017.xlsx")
indicator_2018 <- read_excel("Shared_Data/Economic Indicators(China)2018.xlsx")
indicator_2019 <- read_excel("Shared_Data/Economic Indicators(China)2019.xlsx")
indicator_2020 <- read_excel("Shared_Data/Economic Indicators(China)2020.xlsx")
indicator_2021 <- read_excel("Shared_Data/Economic Indicators(China)2021.xlsx")
indicator_2022 <- read_excel("Shared_Data/Economic Indicators(China)2022.xlsx")

```

```{r}
#| 2016-2022-providence-import-data

# Set the directory path where the files are located
folder_path <- "Shared_Data"

# List all the files in the folder
file_list <- list.files(folder_path)

# Create an empty list to store the data from each file
data_list <- list()

# Iterate over the file list using a for loop
for (file_name in file_list) {
  # Check if the file name meets criteria
  if (grepl("^Economic Indicators\\(China\\)\\d{4}\\.xlsx$", file_name) | grepl("^Economic Indicators\\(China\\)\\.xlsx$", file_name)) {
    file_path <- file.path(folder_path, file_name)
    file_data <- read_xlsx(file_path, na = "--")
    # New column indicating year
    file_data$year <- str_extract(file_name, "\\d{4}") |> as.numeric()
    # Converts all but Region to doubles
    data_list[[file_name]] <- file_data |>
      #mutate_if(is.character, list(~na_if(., "--"))) |>
      mutate(across(-Region, as.numeric))
  }
}

# Merge files
providence_only <- bind_rows(data_list) |> 
  filter(Region != c("China", "Source: Wind")) |>
  group_by(year)

providence_only |> write_csv(file = "data/E_I(2016-2022).csv")
providence_only |> write_excel_csv(file = "data/E_I(2016-2022).xlsx")

# Ask about Economic Indicators(Xiangxi).xlsx

```

```{r}
#| 2022-providence-region-import-data

folder_path_2 <- "Shared_Data/provincial_lgfv"
file_list_2 <- list.files(folder_path_2)
data_list_2 <- list()

for (file_name in file_list_2) {
  if (grepl("^Economic Indicators", file_name)) {
    file_path_2 <- file.path(folder_path_2, file_name)
    file_data_2 <- read_xlsx(file_path_2, na = "--")
    file_data_2$Province <- str_match(file_name, "\\((.*?)\\)")[, 2]
    data_list_2[[file_name]] <- file_data_2 |>
      #mutate_if(is.character, list(~na_if(., "--"))) |>
      mutate(across(-c(Province, Region), as.numeric))
  }
}

cleaned <- bind_rows(data_list_2) |>
  filter(Region != "Source: Wind") |>
  group_by(Province)

cleaned$Region <- gsub("Dist", "", cleaned$Region)
cleaned$Region <- gsub("\\(Inner Mongolia", "", cleaned$Region)
cleaned$Province <- gsub("\\(Inner Mongolia", "", cleaned$Province)
cleaned$Province <- gsub("Neimenggu", "Inner Mongolia", cleaned$Province)
cleaned$Region <- gsub("\\bBaisha\\b", "Baishali", cleaned$Region)

cleaned

cleaned |> write_csv(file = "data/E_I(all provinces).csv")

# IMPORTANT: figure out why Aral, Xinjiang has not city code 
# (it's located/surrounded within Asku, Xinjiang)
# Ask what to do if there are two of the same row in the city-code data (Banan, Chongqing)

# Cities with no code:
# - Aral, Xinjiang
# - Baodi, Tianjin
# - Bayannur, Inner Mongolia

# Cities with two instances:
# - Baoshan, Shanghai and Baoshan, Yunnan

```

```{r}
#| merge-economy-and-finaical-2022

economy_2022 <- read_excel("Shared_Data/Economic Indicators(China)2022.xlsx", sheet = 2)
finaical_2022 <- read_excel("Shared_Data/Economic Indicators(China)2022.xlsx", sheet = 3)

efs_2022 <- full_join(economy_2022, finaical_2022, by = join_by(Region)) |>
  mutate_if(is.character, list(~na_if(., "--"))) |>
  mutate(across(-c(Region), as.numeric))

efs_2022 |> write_csv(file = "data/efs_2022.csv")
efs_2022 |> write_excel_csv(file = "data/efs_2022.xlsx")
  
```


```{r}
#| id-integration-version-1

city_names_codes <- read_excel("Shared_Data/NewFixedCode.xlsx")

code <- city_names_codes
# Removes duplicate rows, ignoring item number
code <- code[!duplicated(select(code, -Item)), ] 

# Removes unnecessary wording from Region names
code$Region <- str_remove_all(code$Region,
  paste(c(" (?i)area",
          " (?i)league",
          " (?i)district",
          " (?i)new (?i)district",
          " (?i)county", 
          " (?i)city", 
          " (?i)administration",
          " (?i)autonomous (?i)county",
          " (?i)autonomous (?i)region",
          " (?i)new (?i)area",
          " (?i)administrative (?i)region",
          " (?i)administrative (?i)prefecture",
          " (?i)autonomous (?i)prefecture",
          " Tibetan Qiang",
          " Li Miao"),
        collapse = "|"))

# Removes unnecessary wording from Province names
code$Province <- str_remove_all(code$Province,
  paste(c(" (?i)province",
          " (?i)autonomous (?i)region",
          " (?i)autonomous (?i)prefecture",
          " (?i)uygur"),
        collapse = "|"))

# Adds city codes to each location in cleaned
merged_df <- merge(cleaned, code, by = c("Region", "Province"), all.x = TRUE)
# merged_df <- merge(cleaned, code, by = "Region", all.x = TRUE)

na_checker <- merged_df |> filter(is.na(`2019_code`)) 
all_good <- merged_df |> filter(!is.na(`2019_code`))

# Task: determine why cities are in na_checker

cleaned_2 <- all_good |> select(!c(prov_name, prov_sname, `2019_sname`, `2019_name`))

cleaned_2 |> write_csv(file = "data/in_progress_ei_provinces.csv")
cleaned_2 |> write_excel_csv(file = "data/in_progress_ei_provinces.xlsx")

```

```{r}
# 
#
# 
# folder_path_3 <- "Shared_Data/provincial_lgfv"
# file_list_3 <- list.files(folder_path_3)
# data_list_3 <- list()
# 
# for (file_name in file_list_3) {
#   if (grepl("^LGFV", file_name)) {
#     file_path_3 <- file.path(folder_path_3, file_name)
#     file_data_3 <- read_xlsx(file_path_3, na = "--") |>
#       separate(col = Region, into = c("Province", "City"), sep = "-")
#     data_list_3[[file_name]] <- file_data_3 |>
#       mutate(
#         across(c(Ranking, 
#                  `Outsatanding Bonds(CNY,B)`, 
#                  `Accumulated Bonds(CNY,B)`,
#                  `Total Assets(CNY,B)`,
#                  `Asset-liability Ratio(%)`,
#                  `Government Subsidy(10K)`,
#                  `Non-Standard Financing(CNY,B)`
#                  ), as.numeric))
#   }
# }
# 
# 
# 
# # cleaned <- bind_rows(data_list_2) |> 
# #   filter(Region != "Source: Wind") |>
# #   group_by(Providence)
# # cleaned
# # 
# # cleaned |> write_csv(file = "data/E_I(all provinces).csv")

```

